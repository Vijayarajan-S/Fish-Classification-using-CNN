{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vijayarajan-S/Fish-Classification-using-CNN/blob/main/cnnfishclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBw0TZEzDpYd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNSxPl8mFuAD",
        "outputId": "03a2b8bd-7e3a-4666-df59-5c63d1735955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Retrieving folder contents\n",
            "Processing file 1GHqB7F1AYocMbiUcqOa4VFtw5mJH0wmb Dataset.zip\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1GHqB7F1AYocMbiUcqOa4VFtw5mJH0wmb\n",
            "From (redirected): https://drive.google.com/uc?id=1GHqB7F1AYocMbiUcqOa4VFtw5mJH0wmb&confirm=t&uuid=6627996b-20a1-45fa-99bf-e4989944c71c\n",
            "To: /content/Dataset/Dataset.zip\n",
            "100% 271M/271M [00:03<00:00, 82.9MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "\n",
        "# Use gdown with the folder link\n",
        "!gdown --folder https://drive.google.com/drive/folders/1iKdOs4slf3XvNWkeSfsszhPRggfJ2qEd -O /content/Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQy_gqCJGI-v",
        "outputId": "a7a70a58-119f-4a59-dfa2-10ce61b8c1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/Dataset/Dataset.zip\n",
            "replace images.cv_jzk6llhf18tm3k0kyttxz/readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip '/content/Dataset/Dataset.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6WLjNFIGoXO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Set paths\n",
        "train_dir = \"/content/images.cv_jzk6llhf18tm3k0kyttxz/data/train\"\n",
        "val_dir = \"/content/images.cv_jzk6llhf18tm3k0kyttxz/data/val\"\n",
        "test_dir = \"/content/images.cv_jzk6llhf18tm3k0kyttxz/data/test\"\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(224, 224),  # resize all images to 224x224\n",
        "    batch_size=16,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms_bcWymG0kv"
      },
      "outputs": [],
      "source": [
        "num_classes = 11\n",
        "model=Sequential()\n",
        "\n",
        "# Block 1\n",
        "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(224,224,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Block 2\n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Block 3\n",
        "model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Block 4\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAmbwy4M3BHA"
      },
      "outputs": [],
      "source": [
        "class_names = train_dataset.class_names\n",
        "print(class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9ECz9a6ikP6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0roBTlCGG_kd"
      },
      "outputs": [],
      "source": [
        "# Get one batch from your training dataset\n",
        "x_batch, y_batch = next(train_dataset.as_numpy_iterator())\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(x_batch[i].astype(\"uint8\"))\n",
        "    plt.title(f\"Label: {y_batch[i]}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7ixjpdaXIaYe",
        "outputId": "4eb786ef-8c85-43bf-8f9a-17b9d1c4850e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5703 - loss: 1.4480\n",
            "Epoch 1: val_accuracy improved from -inf to 0.60073, saving model to best_model.keras\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1277s\u001b[0m 3s/step - accuracy: 0.5706 - loss: 1.4468 - val_accuracy: 0.6007 - val_loss: 1.4274\n",
            "Epoch 2/10\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8503 - loss: 0.4520\n",
            "Epoch 2: val_accuracy improved from 0.60073 to 0.78480, saving model to best_model.keras\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1257s\u001b[0m 3s/step - accuracy: 0.8503 - loss: 0.4520 - val_accuracy: 0.7848 - val_loss: 0.6144\n",
            "Epoch 3/10\n",
            "\u001b[1m339/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2:36\u001b[0m 3s/step - accuracy: 0.8912 - loss: 0.3143"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "\n",
        "# TensorBoard log\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(\n",
        "    log_dir=log_dir,\n",
        "    histogram_freq=1,\n",
        "    write_graph=True,\n",
        "    write_images=True\n",
        ")\n",
        "\n",
        "# Save best model\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    \"best_model.keras\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10,\n",
        "    callbacks=[tensorboard_callback, checkpoint_callback]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkdCwo7Hqgqq"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_dataset)\n",
        "print(predictions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zD4r6WXxudU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_batch, y_batch = next(iter(test_dataset))\n",
        "batch_predictions = model.predict(x_batch)\n",
        "batch_classes = np.argmax(batch_predictions, axis=1)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(x_batch[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(f\"Pred: {batch_classes[i]}, True: {y_batch[i].numpy()}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr3qHqz18j2J6cHdZeZlDc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}